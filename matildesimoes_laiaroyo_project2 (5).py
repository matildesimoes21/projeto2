# -*- coding: utf-8 -*-
"""MatildeSimoes_LaiaRoyo_Project2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VfLqjscKM7HPqfA4ZHbSRpYXDbb1oRE3

# Visualization of information - Project 2
## Grau en CiÃ¨ncia i Enginyeria de Dades
### Laia Royo and Matilde Simoes
"""

import pandas as pd
import altair as alt
import ipywidgets as widgets
!pip install vl-convert-python>=1.6.0
!pip install altair vega_datasets altair_viewer
!pip install "vegafusion[embed]>=1.5.0"
alt.data_transformers.enable('vegafusion')
import matplotlib.colors as mcolors
import seaborn as sns

"""## Part 1 - Cleaning Data

### Data Cleaning and Preprocessing for the Gun Violence Dataset  

To address challenges encountered in a previous project and ensure a clean dataset, we implemented the following steps:  

1. **Data Import and Parsing**  
   The dataset was imported correctly, ensuring all variables were properly separated into distinct columns. This step resolved potential issues with mixed data formats.  

2. **Data Type Standardization**  
   Variables were transformed to their appropriate data types. For example:  
   - Columns such as *Victims Killed*, *Victims Injured*, *Suspects Killed*, and *Suspects Injured* were converted to numerical formats.  
   - The *Incident Date* column was standardized to a date format.  

3. **Missing Data Handling**  
   A thorough check for missing or blank values was performed, confirming that no such issues were present in the dataset.  

4. **Outlier Detection**  
   Using faceted visualizations, we reviewed all numerical variables to detect potential outliers. While no illogical values, such as negative casualty numbers, were found, some unusually large values were identified. Upon inspection, these values were deemed plausible representations of real cases.  

5. **Text Standardization and Clustering**  
   Categorical and text-based variables were standardized using clustering techniques to identify and merge inconsistent entries. For instance, two records were found where the same county had been recorded with different names, and this inconsistency was corrected.  

6. **Creation of the 'State Code' Column**  
   A new column, *State Code*, was added to facilitate future visualizations. This column contains state codes compatible with Altair, ensuring consistency across the dataset and simplifying analysis and graphical representation.  

7. **Cleaning the 'City or County' Column**  
   To create a robust and integrated dataset, we transformed city names into county names using geospatial data. The steps included:  
   - Creating two new columns for latitude and longitude based on the address using the following query:  
     `info = "https://nominatim.openstreetmap.org/format=json&q=" + address`  
     Extracted values: `info.lat` and `info.lon`.  
   - Retrieving detailed county information using the coordinates:  
     `"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x=" + lon + "&y=" + lat + "&benchmark=Public_AR_Census2020&vintage=Census2020_Census2020&format=json"`.  
   - Parsing the JSON response to extract county names:  
     `parseJson(value)["result"]["geographies"]["Counties"][0]["NAME"]`.  

8. **Adding 'Region' and 'Population' Columns**  
   Two additional columns were created:  
   - *Region*: This column categorizes records based on regions.  
   - *Population*: This column accounts for population data, dependent on the year and state. (This step was implemented using Python.)  

9. **Date Transformation**  
   The *Date* column was split into two new columns: *Year* and *Month*. This transformation was completed with the assistance of OpenRefine.  

Data population source: https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html

Data region source: https://www.mappr.co/political-maps/us-regions-map/
"""

# we read population data and concatenate them into a single DataFrame
population_files = [
    'population2018.csv', 'population2019.csv', 'population2020.csv',
    'population2021.csv', 'population2022.csv', 'population2023.csv'
]
population_dfs = [pd.read_csv(file) for file in population_files]
population = pd.concat(population_dfs)

# we read cleaned gun violence data
gun_data = pd.read_csv('cleandata_GunViolenceAllYears_project2.csv')

# no an state
gun_data = gun_data[gun_data['State'] != 'District of Columbia']

# we merge datasets using the key = (State Code, Year)
gun_data = gun_data.merge(population, on=('State Code', 'Year'))

# we create a new column called quadrimester to aggregate data
month_to_quadrimester = {
    'gener': 1, 'febrer': 1, 'marÃ§': 1, 'abril': 1,  # 1st quadrimester
    'maig': 2, 'juny': 2, 'juliol': 2, 'agost': 2,  # 2nd quadrimester
    'setembre': 3, 'octubre': 3, 'novembre': 3, 'desembre': 3  # 3rd quadrimester
}

gun_data['Quadrimester'] = gun_data['Month'].map(month_to_quadrimester)
gun_data['Quadrimester_Label'] = gun_data['Year'].astype(str) + '-Q' + gun_data['Quadrimester'].astype(str)

# now, data is ready to implement visualizations
gun_data.head()

"""## Part 2 - Visualization"""

# we choose unique values for each state related on their region
regions = gun_data['Region'].unique()
states_by_region = gun_data.groupby('Region')['State'].unique()
region_palette = sns.color_palette("tab10", len(regions))
region_colors = {region: mcolors.rgb2hex(color) for region, color in zip(regions, region_palette)}

# and we save it on a diccionary
state_colors = {}
for region in regions:
    states = states_by_region[region]
    shades = sns.blend_palette(
        [region_palette[regions.tolist().index(region)], (0.8, 0.8, 0.8)],
        n_colors=len(states),
        input="rgb"
    )
    state_colors.update({state: mcolors.rgb2hex(color) for state, color in zip(states, shades)})

# we aggregate data by region, state and county
state_agg = gun_data.groupby(['Quadrimester_Label', 'Year', 'State', 'State Code']).size().reset_index(name='Count')
state_agg.rename(columns={'State Code': 'id'}, inplace=True)
region_agg = gun_data.groupby(['Quadrimester_Label', 'Year', 'Region', 'State', 'State Code']).size().reset_index(name='Count')
region_agg.rename(columns={'State Code': 'id'}, inplace=True)
county_agg = gun_data.groupby(['Quadrimester_Label', 'Year', 'County', 'State']).size().reset_index(name='Count')

"""### Q1: How has the number of mass shootings evolved in the big US regions between two concrete years? For this, we need you to aggregate the data in the 5 regions and let the user select the first and last year of the comparison. Same for states, both views coordinated."""

def update_chart_q1_state(year_range):
    """
    Updates the chart based on the year range, type of data (State or Region), and selected states.
    """
    states = alt.topo_feature('https://vega.github.io/vega-datasets/data/us-10m.json', feature='states')

    # we create a selector
    selector = alt.selection_point(fields=['State'], value=[], name='SelectedStates', empty='all')

    # we create the selection map
    state_map = alt.Chart(states).mark_geoshape().encode(
        tooltip=alt.Tooltip('State:N', title='State'),
        color=alt.condition(
            selector,
            alt.Color('State:N', scale=alt.Scale( # using the palette choosen begofore
                    domain=list(state_colors.keys()),
                    range=list(state_colors.values())
                ),
                legend=None
            ),
            alt.value('lightgray') # if not selected, grey
        )
    ).transform_lookup(
        lookup='id',
        from_=alt.LookupData(state_agg, 'id', ['State'])
    ).project(
        type='albersUsa'
    ).properties(
        title='Gun Violence Incidents by State',
        width=500,
        height=300
    ).add_params(selector)

    filtered_data = state_agg[(state_agg['Year'] >= year_range[0]) & (state_agg['Year'] <= year_range[1])]

    # we create the line chart
    scatter = alt.Chart(filtered_data).mark_line().encode(
        x=alt.X('Quadrimester_Label:O', title='Quadrimester'),
        y=alt.Y('Count:Q', title='Incident Count', scale=alt.Scale(domain=[0, 50])),
        color=alt.Color('State:N', title='State', scale=alt.Scale(domain=list(state_colors.keys()), range=list(state_colors.values()))),
        tooltip=['State:N', 'Count:Q'],
        opacity=alt.condition(selector, alt.value(1), alt.value(0.1))
    ).properties(
        width=800,
        height=400
    ).transform_filter(
        selector # filtered by the selector
    )

    # we combine selectors
    combined_chart = state_map | scatter
    return combined_chart

example1 = update_chart_q1_state([2020, 2022])
example1

"""### Q2: Given a concrete year, how has the number of mass shooting per citizen grown or decreased across the different regions in the US compared to the first year of sampled data?"""

def update_chart_q2(selected_year):

    # we filter data for the selected year and the first year in the dataset
    comparison_data = gun_data[gun_data['Year'].isin([selected_year[0], selected_year[1]])]

    # we check if range is ok
    if comparison_data.empty:
        print("Minimum and maximum year should be diferent")

    comparison_data_grouped = comparison_data.groupby(['Year', 'Region']).size().reset_index(name='Incident Count')

    population_data = gun_data[['Region', 'Year', 'Population']].drop_duplicates()
    comparison_data_grouped = comparison_data_grouped.merge(population_data, on=['Region', 'Year'], how='left')

    comparison_data_grouped['Incidents_Per_1M_Citizen'] = (
        comparison_data_grouped['Incident Count'] / comparison_data_grouped['Population'] *1000000
    )

    # we create a line chart to show the growth or decrease over regions
    chart = alt.Chart(comparison_data_grouped).mark_line().encode(
        x=alt.X('Year:O', title='Year'),
        y=alt.Y('Incidents_Per_1M_Citizen:Q', title='Incidents Per 1M Citizen'),
        color=alt.Color('Region:N', title='Region', scale=alt.Scale(domain=list(region_colors.keys()), range=list(region_colors.values()))),
        tooltip=['Region:N', 'Year:O', 'Incident Count:Q', 'Incidents_Per_1M_Citizen:Q']
    ).properties(
        title=f"Comparison of Mass Shootings Per 1M Citizen between {selected_year[0]} and {selected_year[1]}",
        width=800,
        height=400
    )

    return chart

example2 = update_chart_q2([2020,2022])
example2

"""### Q3: For the visualization in Q1, we would like you to be able to select a state, and show the detailed information on the counties of the state."""

def update_chart_q3(year_range, selected_state):

  state_data = gun_data[gun_data['State'] == selected_state]

  # we filter data in the range
  filtered_data = state_data[(state_data['Year'] >= year_range[0]) & (state_data['Year'] <= year_range[1])]

  county_aggregated = filtered_data.groupby(['County', 'Quadrimester_Label']).size().reset_index(name='Incident Count')

  # we sort data by time for proper visualization
  county_aggregated = county_aggregated.sort_values(by='Quadrimester_Label')

  # we create a stacked area chart using Altair
  stacked_area_chart = alt.Chart(county_aggregated).mark_area().encode(
      x=alt.X('Quadrimester_Label:O', title='Month-Year', axis=alt.Axis(labelAngle=-45)),
      y=alt.Y('Incident Count:Q', title='Incident Count'),
      color=alt.Color('County', legend=alt.Legend(columns=2, symbolLimit=50)),
      tooltip=['County:N', 'Incident Count:Q', 'Quadrimester_Label:O']
  ).properties(
      width=800,
      height=400
  )

  # we group by data and sort to obtain the counties with more incidents in total
  top_5_counties = county_aggregated.groupby('County').sum().reset_index().sort_values('Incident Count', ascending=False).head(5)
  top_5_counties = top_5_counties.sort_values('Incident Count', ascending=False).head(5)

  # we create a bar chart
  bar_chart = alt.Chart(top_5_counties).mark_bar().encode(
    x=alt.X('Incident Count:Q'),
    y=alt.Y('County:N', sort='-x'),
    color=alt.Color('County', legend=alt.Legend(title='County')),
    tooltip=['County:N', 'Incident Count:Q']
  )

  return bar_chart & stacked_area_chart

example3 = update_chart_q3([2020,2022], 'Ohio')
example3

"""For the final visualization, we tried to syncronize all the plots using a selector but this was not working, so we should adapt our original idea and use a multiselector. Code in the file 'Code Streamlit'."""